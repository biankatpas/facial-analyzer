"""
M√≥dulo de an√°lise de express√µes faciais
"""

import cv2
import mediapipe as mp
import numpy as np
from deepface import DeepFace
import google.generativeai as genai
from datetime import datetime
import json
from collections import deque
import time


class FacialExpressionAnalyzer:
    """Analisador de express√µes faciais em tempo real"""
    
    def __init__(self, gemini_api_key=None):
        """
        Inicializa o analisador
        
        Args:
            gemini_api_key: Chave API do Google Gemini (opcional)
        """
        # MediaPipe para detec√ß√£o de face
        self.mp_face_detection = mp.solutions.face_detection
        self.mp_drawing = mp.solutions.drawing_utils
        self.face_detection = self.mp_face_detection.FaceDetection(
            model_selection=1, 
            min_detection_confidence=0.5
        )
        
        # Configura√ß√£o Gemini
        self.model = None
        if gemini_api_key:
            try:
                genai.configure(api_key=gemini_api_key)
                self.model = genai.GenerativeModel('gemini-1.5-flash')
                print("‚úÖ Gemini AI configurado")
            except Exception as e:
                print(f"‚ö†Ô∏è  Gemini n√£o configurado: {e}")
        
        # Armazenamento
        self.emotion_history = deque(maxlen=100)
        self.analysis_results = []
        
    def detect_face(self, frame):
        """
        Detecta faces no frame
        
        Returns:
            list: Coordenadas das faces [(x, y, w, h), ...]
        """
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_detection.process(rgb_frame)
        
        faces = []
        if results.detections:
            h, w, _ = frame.shape
            for detection in results.detections:
                bbox = detection.location_data.relative_bounding_box
                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                faces.append((x, y, width, height))
        
        return faces
    
    def analyze_emotion(self, frame):
        """
        Analisa emo√ß√µes usando DeepFace
        
        Returns:
            dict: {'emotions': {...}, 'dominant': str, 'timestamp': str}
        """
        try:
            analysis = DeepFace.analyze(
                frame, 
                actions=['emotion'],
                enforce_detection=False,
                silent=True
            )
            
            if isinstance(analysis, list):
                analysis = analysis[0]
            
            return {
                'emotions': analysis.get('emotion', {}),
                'dominant': analysis.get('dominant_emotion', 'unknown'),
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            print(f"Erro na an√°lise: {e}")
            return None
    
    def process_video_stream(self, duration=30, question=""):
        """
        Processa stream de v√≠deo da webcam
        
        Args:
            duration: Dura√ß√£o em segundos
            question: Pergunta sendo respondida
            
        Returns:
            list: Lista de an√°lises de emo√ß√µes
        """
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            raise RuntimeError("‚ùå N√£o foi poss√≠vel acessar a webcam")
        
        start_time = time.time()
        frame_count = 0
        session_emotions = []
        
        print(f"\nüé• Gravando: '{question}'")
        print(f"‚è±Ô∏è  Dura√ß√£o: {duration}s | Pressione 'q' para parar\n")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            elapsed = time.time() - start_time
            if elapsed >= duration:
                break
            
            # Detecta faces
            faces = self.detect_face(frame)
            
            # Analisa emo√ß√µes (a cada 10 frames)
            if frame_count % 10 == 0 and faces:
                emotion_data = self.analyze_emotion(frame)
                if emotion_data:
                    session_emotions.append(emotion_data)
                    self.emotion_history.append(emotion_data)
            
            # Desenha ret√¢ngulos
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            # Exibe emo√ß√£o atual
            if session_emotions:
                emotion = session_emotions[-1]['dominant']
                cv2.putText(frame, f"Emocao: {emotion}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.8, (0, 255, 0), 2)
            
            # Timer
            remaining = int(duration - elapsed)
            cv2.putText(frame, f"Tempo: {remaining}s", 
                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 
                       0.8, (255, 255, 255), 2)
            
            cv2.imshow('Analise Facial - RH', frame)
            frame_count += 1
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
        # Armazena resultado
        if session_emotions:
            self.analysis_results.append({
                'question': question,
                'emotions': session_emotions,
                'duration': elapsed,
                'timestamp': datetime.now().isoformat()
            })
        
        return session_emotions
    
    def generate_emotion_summary(self, emotions_list):
        """Gera resumo estat√≠stico das emo√ß√µes"""
        if not emotions_list:
            return {}
        
        emotion_counts = {}
        for entry in emotions_list:
            for emotion, score in entry['emotions'].items():
                if emotion not in emotion_counts:
                    emotion_counts[emotion] = []
                emotion_counts[emotion].append(score)
        
        summary = {}
        for emotion, scores in emotion_counts.items():
            summary[emotion] = {
                'media': round(np.mean(scores), 2),
                'max': round(np.max(scores), 2),
                'min': round(np.min(scores), 2)
            }
        
        return summary
    
    def generate_ai_insights(self, question, emotions_summary):
        """Gera insights usando Gemini AI"""
        if not self.model:
            return "‚ö†Ô∏è  API Gemini n√£o configurada"
        
        prompt = f"""
        Analise o resultado de reconhecimento facial durante entrevista:
        
        Pergunta: {question}
        
        Emo√ß√µes detectadas (% m√©dia):
        {json.dumps(emotions_summary, indent=2, ensure_ascii=False)}
        
        Como especialista em RH, forne√ßa:
        1. Interpreta√ß√£o das emo√ß√µes dominantes
        2. Insights sobre o estado emocional
        3. Pontos de aten√ß√£o para o recrutador
        4. Sugest√µes de perguntas de follow-up
        
        Seja profissional e evite conclus√µes definitivas.
        """
        
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"Erro ao gerar insights: {e}"
    
    def export_report(self, filename="/app/reports/analise_candidato.json"):
        """Exporta relat√≥rio completo em JSON"""
        report = {
            'data_analise': datetime.now().isoformat(),
            'total_perguntas': len(self.analysis_results),
            'sessoes': []
        }
        
        for session in self.analysis_results:
            emotions_summary = self.generate_emotion_summary(session['emotions'])
            
            session_report = {
                'pergunta': session['question'],
                'duracao_segundos': round(session['duration'], 2),
                'timestamp': session['timestamp'],
                'resumo_emocoes': emotions_summary,
                'total_frames_analisados': len(session['emotions'])
            }
            
            # Gera insights com IA
            if self.model:
                session_report['insights_ia'] = self.generate_ai_insights(
                    session['question'], 
                    emotions_summary
                )
            
            report['sessoes'].append(session_report)
        
        # Salva arquivo
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\n‚úÖ Relat√≥rio exportado: {filename}")
        return report
